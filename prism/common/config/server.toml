# NOTE: all of these settings can be passed from the ENV using the prefix "PRISM_SERVER_"
#       all names are case insensitive

# until we have cryptographic sortition, statically configure the roles of this server here:
roles = []
# dropbox index (only used in roles DROPBOX*), meaningful values are >= 0:
db_index = -1

# MPC-related environment variables:
party_ids = []

# for the TCP PrismTransport channel, what port to use
prism_socket_port = 7871

# if >0 then sleep initially for a random number of seconds in
# interval ]0; delay[ to de-sync servers; set to 0 to avoid any delay
delay = 1
delay_fixed = 2

# PKI stuff:  TODO: implement in PRISM config generator functions to generate these in Docker images
# TODO: if testing manually (outside Docker) then follow README-PKI.md instructions
# ===
# load Root CA certificate from this file:
pki_root_cert_file = ""
# if set, then load Root CA private key from this file and self-issue/-sign all server certificates (for scale up testing)
pki_root_private_key_file = ""
# if root private key above not set, then use the directory from `pki_root_cert_file` to look for structure like this:
#   epoch_000/  # genesis
#             *-server-00001_key.pem, *-server-00001_cert.pem,
#             *-server-00002_key.pem, *-server-00002_cert.pem,
#             [...]  # for all servers
#   epoch_001/  # first switched-to epoch
#             *-server-00001_key.pem, *-server-00001_cert.pem, [...]
#   [...]  # for certain number of epochs

# maximum time in each role, given as minutes; if 0 then never change role and stay always on
# 24h = 1440 minutes
cs2_max_time = 0
# set this to percent of choosing ON state (= weight of the random choice between ON and OFF states);
# if < 0 or > 100, will set to 50% probability of choosing ON
cs2_weight_on = -1
# time to periodically send ARK messages, given as minutes and can be fractions;
# if 0 then make ARK stay forever and don't repeat sending it -> not recommended!
cs2_ark_timeout = 1
# ARK expiration factor: use this to set the expiration time as a multiple of the ARK timeout
# values < 1 are set to 1
cs2_ark_expiration_factor = 2
# broadcast known ARKs to connected clients (using *client address) at a fixed rate in seconds:
cs2_ark_sleep_time = 10
# The largest package of ARKs (in bytes) we're willing to send at once
cs2_arks_max_mtu = 30000

# EMIXes should update clients as they discover servers have become unreachable
nark = true
# Wait to check on reachability before sending NARK about no longer reachable servers
nark_confirmation_seconds = 10
# Sleep this long before checking reachability and confirmation again to determine any NARK messages
nark_timeout_seconds = 10
# If set to True, will allow at time of updating the routing table to short-circuit the waiting times above:
nark_allow_cancel = false

# link-state routing variables
# rate-limiting of queue processing (send, ACK, TODO: retransmission?) in seconds
ls_q_rate_limit = 0.001
# refresh own LSP at a fraction of TTL
ls_own_refresh = 0.66
# default value for Link-State Protocol message TTL field in seconds, 60 min = 1800s
ls_time_to_live = 3600
# TTL maximum is given as seconds: 1h = 60m = 3600s
ls_ttl_max = 3600
# this value should be around the diameter of the network:
ls_hops_max = 7
# define neighbor discovery frequency by sleeping in between [in seconds]:
ls_neighbor_discovery_sleep = 45
# only try this many times to establish LS neighbor on <address, link_id> before giving up
# if set to 0 then never stop trying to reach Links that are present in Dynamic Transport
# NOTE: these attempts are solely for unknown neighbors; and, all attempts to a potential, yet unknown neighbor get
#       reset when we hear an LSP HELLO from them
ls_max_discovery_attempts = 3
# timeout for LSP HELLO and HELLO RESPONSE messages [in ms]:
ls_neighbor_timeout_ms = 10000
# timeout factor (for ARK frequency), when to issue another LSP Hello message to neighbors we haven't heard from:
ls_alive_factor = 1.5
# timeout after trying to keep neighbor alive or send failures to wait for sign of life [in seconds]:
ls_presumed_dead_timeout = 10
# try only this many times to forward a message:
ls_n_tries_fowarding = 3
# wait this many seconds in between trying to forward a message:
ls_sleep_try_forwarding = 25

# The time to wait for timeout on replies to clients
db_reply_timeout = 120.0

# Lock-free MPC parameters
# The number of parties to generate secret sharing systems for
mpc_nparties = 4
# The number of parties needed to recover a secret
threshold = 2
# This is for prime modulus for finite field calculations. Should be greater than NBYTES_MESSAGE_CHUNK(in bits) = 32.
# But keeping it low will help reduce the bandwidth per server
mpc_nbits_modulus = 257
# Encrypt MPC peer traffic once half-keys are exchanged
mpc_lf_encrypt_peer = true
# The number of find operations to generate preproducts for
mpc_preproduct_batch_size = 200
# When less than this fraction of preproducts remain for a given peer group, trigger batch generation
mpc_preproduct_refresh_threshold = 0.25
# Only send enough fragments back to the client for minimal reconstruction
mpc_lf_minimal_replies = true
# The maximum number of fragments to check in a single find operation
mpc_lf_find_limit = 10
# The number of seconds per batch item to wait for preproduct generation
mpc_lf_batch_timeout = 0.1
# The number of seconds to wait for a store op to complete before retrying
mpc_lf_store_timeout = 30.0
# The number of seconds per fragment to wait for a retrieve op
mpc_lf_find_timeout = 1.0
# The number of concurrent store/find operations to allow
mpc_lf_concurrent_store_limit = 10
mpc_lf_concurrent_find_limit = 5
# The time to wait for MPC_HELLO acks, and the time to wait between hello attempts
mpc_lf_hello_timeout = 10.0
# The base timeout for check ops
mpc_lf_check_timeout = 10.0
mpc_lf_retrieve_timeout = 20.0
# The base timeout for waiting during ops
mpc_lf_base_op_timeout = 10.0
# the time to wait between trying to reply
mpc_lf_reply_retry_seconds = 10.0

# set this to False to not fall back to broadcasting if no link/route to unicast destination known
emitting_broadcast_fallback = false
# set this to False if you want to try emitting on ALL available transports and not stop after the first success
emitting_stop_after_success = true
# the number of seconds emit() will wait to retry if sending a message fails
sleep_try_emitting = 10
# the number of tries emit() will make to send a message
emit_retries = 1

# timeouts for sends of ARKs and NARKs
emit_nark_timeout_ms = 60000
emit_ark_timeout_ms = 120000

# mix strategies for EMIX:
mix_strategy = "POISSON"  #or "POOL", if not set uses "DEFAULT" = idempotent
mix_poisson_lambda = 0.5  # average delay for Poisson-mixed messages: lambda secs (exponentially with scale=1/lambda)
mix_pool_size = 10
mix_pool_flush_ratio = 0.7  # 70% flushed after pool size reached
mix_pool_timeout = -1
# Forwarding retries for EMIX:
mix_forward_retry_delay_sec = 30.0
mix_forward_retry_limit = 120

# TCP sockets for unicast:
tcp_socket_reconnect_after = 10.0  # seconds to try and re-connect to a TCP socket
# TODO: TLS support
# testing settings to make TCP less performant (simulating TA2 channels):
# socket_test_drop = 0.0  # up to 1.0, which will drop 1005 of messages
# socket_test_delay = 0.0  # delay will be randomly chosen in [0; delay] interval

# VRF (Cryptographic Sortition) parameters (defaults for very small number of servers ~10):
vrf_p_off = 0
vrf_p_emix = 0.3
vrf_n_ranges = 1
vrf_m_replicas = 1
vrf_seed = 0  # if 0 then don't seed PRNG
# VRF topology:
vrf_c_p_factor = 3.0  # factor c for random link probabilities: p=c*ln(n)/n or p_i=c*ln(n)/(n*i) for b=0 or >0
vrf_b_db_emix = 2     # two EMIXes per DB leader; if b=0 then induce ER random graph with uniform p=c*ln(n)/n
# Online VRF topology settings
vrf_topology_ring = true   # Whether to connect all EMIXes in a giant ring by pseudonym order
vrf_link_probability = 0.3 # The probability that non-ring-linked EMIXes will connect to each other
vrf_outer_link_probability = 1.0 # The proability that outer nodes (Dropbox, Dummy, etc) will be compatible with a given EMIX

# The number of EMIXes outer servers try to link to
other_server_emix_links = 3

# Flooding during epoch switching:
flood_via_direct_only = true  # if false, also use indirect links (in addition to direct links)
flood_max_hops = 0  # if >0 then stop forwarding after this many hops
flood_gossip_r = 0  # if 0 then flood to ALL available links;
                    # if ]0..1[ then use as probability for forwarding on each link (independent random choice);
                    # if 1, 2,... then use as number of randomly chosen links to forward to
flood_spread_seconds = 0  # if >0 spread sending to all N links over interval [0; x] seconds but with random distances
